# -*- coding: utf-8 -*-
"""Q2 Group Project

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1aeI-8Q2GxAvEUHy3nDztySwy_MV-lVBu
"""

import requests
from bs4 import BeautifulSoup
import pandas as pd
import json

url = 'https://en.wikipedia.org/wiki/AFI%27s_100_Years...100_Movies'

page = requests.get(url)

page.status_code

webpage = BeautifulSoup(page.content, 'html.parser')

print(webpage)

x = webpage

title = []
year = []
producer = []
rows = x.find_all('tr')
for x in rows:
  cells = x.find_all('td')
  if len(cells) == 6:
     #print(cells[0].get_text(), cells[1].get_text(), cells[3].get_text())
     title.append(cells[0].get_text())# apend to the list
     year.append(cells[1].get_text())
     producer.append(cells[3].get_text())

print(title)

DF1 = pd.DataFrame ({
    'Title': title,
    'Year': year,
    'Producer': producer
})
#this is the first data frame
#Now we need to connect the API Maybe the finance API or what the prof said we can input it into a New York Times API

print(DF1)

# #setting the API Key
# import http.client

# conn = http.client.HTTPSConnection("movies-ratings2.p.rapidapi.com")

# headers = {
#     'x-rapidapi-key': "c55a06b11cmsh5b09bdd5a3b9a4bp10b8f1jsn26a623feecfc",
#     'x-rapidapi-host': "movies-ratings2.p.rapidapi.com"
# }

# conn.request("GET", "/ratings?id=[title]", headers=headers)
# data = conn.getresponse()
# print(data.read())

title

"""Looking up movie data (scraped from wikipedia) in the API"""

import json
import time
import pandas as pd
import requests


# Your list of classic movies
movies = title[:31]

# OMDB API Key - you need to get your own free API key from http://www.omdbapi.com/
OMDB_API_KEY = "c9b84aa0"
# List to store all movie data
all_movie_data = []

# Process all movies
for i, movie_title in enumerate(movies, 1):
    print(f"Processing {i}/{len(movies)}: {movie_title}")

    # Search for the movie using OMDB API
    omdb_url = f"http://www.omdbapi.com/?apikey={OMDB_API_KEY}&t={movie_title}&type=movie&plot=full"

    try:
        response = requests.get(omdb_url)
        omdb_data = response.json()

        if omdb_data.get('Response') == 'True':
            print(f"Found data for {movie_title}")

            # Create a dictionary with the movie information
            movie_info = {
                'title': omdb_data.get('Title', movie_title),
                'year': omdb_data.get('Year', 'N/A'),
                'rated': omdb_data.get('Rated', 'N/A'),
                'released': omdb_data.get('Released', 'N/A'),
                'runtime': omdb_data.get('Runtime', 'N/A'),
                'genre': omdb_data.get('Genre', 'N/A'),
                'director': omdb_data.get('Director', 'N/A'),
                'writer': omdb_data.get('Writer', 'N/A'),
                'actors': omdb_data.get('Actors', 'N/A'),
                'plot': omdb_data.get('Plot', 'N/A'),
                'language': omdb_data.get('Language', 'N/A'),
                'country': omdb_data.get('Country', 'N/A'),
                'awards': omdb_data.get('Awards', 'N/A'),
                'poster': omdb_data.get('Poster', 'N/A'),
                'imdb_id': omdb_data.get('imdbID', 'N/A'),
                'imdb_rating': omdb_data.get('imdbRating', 'N/A'),
                'imdb_votes': omdb_data.get('imdbVotes', 'N/A'),
                'box_office': omdb_data.get('BoxOffice', 'N/A'),
                'production': omdb_data.get('Production', 'N/A'),
                'website': omdb_data.get('Website', 'N/A'),
                'original_query': movie_title
            }

            # Extract ratings from different sources (IMDb, Rotten Tomatoes, Metacritic)
            ratings = omdb_data.get('Ratings', [])
            for rating in ratings:
                source = rating.get('Source', '').replace(' ', '_').lower()
                value = rating.get('Value', 'N/A')
                movie_info[f'{source}_rating'] = value

            all_movie_data.append(movie_info)
        else:
            print(f"No results found for: {movie_title}")
            # Add basic entry for movies not found
            all_movie_data.append({
                'title': movie_title,
                'original_query': movie_title,
                'not_found': True
            })
    except Exception as e:
        print(f"Error fetching data for {movie_title}: {e}")
        # Add basic entry for movies with errors
        all_movie_data.append({
            'title': movie_title,
            'original_query': movie_title,
            'error': str(e)
        })

    # Pause to avoid hitting API rate limits (OMDB allows 1000 requests per day)
    time.sleep(0.5)

# Create DataFrame from the collected data
movies_df = pd.DataFrame(all_movie_data)

movies_df

movies_df.to_csv('movies.csv', index=False)

import sqlite3

conn = sqlite3.connect('movies.db')
movies_df.to_sql('movies', conn, if_exists='replace',index=False)
result = pd.read_sql("SELECT * FROM movies", conn)
print(result)

